{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "## Ensembles\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import auc, roc_curve, RocCurveDisplay\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "\n",
    "# Seleção de Feature \n",
    "from sklearn.feature_selection import SelectFromModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 265123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('data_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Abandono_curso'], axis=1)\n",
    "y = df['Abandono_curso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_range_finder\n",
    "models = {}\n",
    "# decision tree classifier\n",
    "models.update( {\"dtc\":DecisionTreeClassifier(random_state=SEED)} )\n",
    "# Gaussian Naive Bayes - testar\n",
    "models.update( {\"gnb\":GaussianNB()} )\n",
    "# k-nearest neighbors\n",
    "models.update( {\"knn\":KNeighborsClassifier()} )\n",
    "# Support Vector Classification Linear\n",
    "models.update( {\"svcl\":LinearSVC(random_state=SEED)} )\n",
    "# Support Vector Classification Polynomial\n",
    "models.update( {\"svcp\":SVC(kernel=\"poly\", random_state=SEED, max_iter=3000)} )\n",
    "# Support Vector Classification Rbf\n",
    "models.update( {\"svcr\":SVC(kernel=\"rbf\", random_state=SEED, max_iter=3000)} )\n",
    "# Mini-Batch K-Means\n",
    "#models.update( {\"mbkmeans\":MiniBatchKMeans(random_state=SEED)} )\n",
    "# random forest\n",
    "models.update( {\"rf\":RandomForestClassifier(random_state=SEED)} )\n",
    "# Stochastic Gradient Descent Classifier\n",
    "models.update( {\"sgd\":SGDClassifier(random_state=SEED)} )\n",
    "# Logistic Regression\n",
    "models.update( {\"lr\":LogisticRegression(random_state=SEED, max_iter=1000)} )\n",
    "# Multilayer Perceptron\n",
    "models.update( {\"mlp\":MLPClassifier(random_state=SEED, max_iter=1000)} ) \n",
    "# Extreme Gradiente Boost\n",
    "models.update( {\"xgb\":XGBClassifier()} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: dtc\n",
      "Training model: gnb\n",
      "Training model: knn\n",
      "Training model: svcl\n",
      "Training model: svcp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: svcr\n",
      "Training model: rf\n",
      "Training model: sgd\n",
      "Training model: lr\n",
      "Training model: mlp\n",
      "Training model: xgb\n"
     ]
    }
   ],
   "source": [
    "trained_models = {}\n",
    "for cls in models.keys():\n",
    "  print(f\"Training model: {cls}\")\n",
    "  trained_models.update({cls:models[cls].fit(X_train, y_train)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving predictions from model: dtc\n",
      "Retrieving predictions from model: gnb\n",
      "Retrieving predictions from model: knn\n",
      "Retrieving predictions from model: svcl\n",
      "Retrieving predictions from model: svcp\n",
      "Retrieving predictions from model: svcr\n",
      "Retrieving predictions from model: rf\n",
      "Retrieving predictions from model: sgd\n",
      "Retrieving predictions from model: lr\n",
      "Retrieving predictions from model: mlp\n",
      "Retrieving predictions from model: xgb\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "for cls in trained_models.keys():\n",
    "  print(f\"Retrieving predictions from model: {cls}\")\n",
    "  predictions.update({cls:trained_models[cls].predict(X_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracies = {}\n",
    "class_rep = {}\n",
    "conf_matr = {}\n",
    "\n",
    "for pred in predictions.keys():\n",
    "  # accuracy scores\n",
    "  accuracies.update( { pred: accuracy_score(y_test, predictions[pred]) } )\n",
    "  # classification reports\n",
    "  class_rep.update( { pred: classification_report(y_test, predictions[pred]) } )\n",
    "  # confusion matrixes\n",
    "  conf_matr.update( { pred: confusion_matrix(y_test, predictions[pred]) } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtc': 0.6759956942949408,\n",
       " 'gnb': 0.759956942949408,\n",
       " 'knn': 0.6663078579117331,\n",
       " 'svcl': 0.3573735199138859,\n",
       " 'svcp': 0.7158234660925726,\n",
       " 'svcr': 0.7158234660925726,\n",
       " 'rf': 0.7631862217438106,\n",
       " 'sgd': 0.28417653390742736,\n",
       " 'lr': 0.7771797631862217,\n",
       " 'mlp': 0.7631862217438106,\n",
       " 'xgb': 0.7416576964477933}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Model: dtc\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.45      0.44       264\n",
      "           1       0.78      0.77      0.77       665\n",
      "\n",
      "    accuracy                           0.68       929\n",
      "   macro avg       0.60      0.61      0.61       929\n",
      "weighted avg       0.68      0.68      0.68       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: gnb\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.30      0.41       264\n",
      "           1       0.77      0.94      0.85       665\n",
      "\n",
      "    accuracy                           0.76       929\n",
      "   macro avg       0.72      0.62      0.63       929\n",
      "weighted avg       0.75      0.76      0.72       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: knn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.16      0.21       264\n",
      "           1       0.72      0.87      0.79       665\n",
      "\n",
      "    accuracy                           0.67       929\n",
      "   macro avg       0.52      0.51      0.50       929\n",
      "weighted avg       0.61      0.67      0.62       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: svcl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.91      0.44       264\n",
      "           1       0.79      0.14      0.24       665\n",
      "\n",
      "    accuracy                           0.36       929\n",
      "   macro avg       0.54      0.52      0.34       929\n",
      "weighted avg       0.65      0.36      0.30       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: svcp\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       264\n",
      "           1       0.72      1.00      0.83       665\n",
      "\n",
      "    accuracy                           0.72       929\n",
      "   macro avg       0.36      0.50      0.42       929\n",
      "weighted avg       0.51      0.72      0.60       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: svcr\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       264\n",
      "           1       0.72      1.00      0.83       665\n",
      "\n",
      "    accuracy                           0.72       929\n",
      "   macro avg       0.36      0.50      0.42       929\n",
      "weighted avg       0.51      0.72      0.60       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.28      0.40       264\n",
      "           1       0.77      0.96      0.85       665\n",
      "\n",
      "    accuracy                           0.76       929\n",
      "   macro avg       0.74      0.62      0.63       929\n",
      "weighted avg       0.75      0.76      0.72       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: sgd\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.99      0.44       264\n",
      "           1       0.50      0.00      0.01       665\n",
      "\n",
      "    accuracy                           0.28       929\n",
      "   macro avg       0.39      0.50      0.22       929\n",
      "weighted avg       0.44      0.28      0.13       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: lr\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.24      0.38       264\n",
      "           1       0.77      0.99      0.86       665\n",
      "\n",
      "    accuracy                           0.78       929\n",
      "   macro avg       0.84      0.61      0.62       929\n",
      "weighted avg       0.81      0.78      0.73       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: mlp\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.17      0.29       264\n",
      "           1       0.75      1.00      0.86       665\n",
      "\n",
      "    accuracy                           0.76       929\n",
      "   macro avg       0.86      0.59      0.58       929\n",
      "weighted avg       0.81      0.76      0.70       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: xgb\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.35      0.43       264\n",
      "           1       0.78      0.90      0.83       665\n",
      "\n",
      "    accuracy                           0.74       929\n",
      "   macro avg       0.68      0.62      0.63       929\n",
      "weighted avg       0.72      0.74      0.72       929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cf in class_rep.keys():\n",
    "  print('------------------------------------------')\n",
    "  print(f\"Model: {cf}\")\n",
    "  print(class_rep[cf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_models = {}\n",
    "# decision tree classifier\n",
    "cv_models.update( {\"dtc\":DecisionTreeClassifier(random_state=SEED)} )\n",
    "# Gaussian Naive Bayes - testar\n",
    "cv_models.update( {\"gnb\":GaussianNB()} )\n",
    "# k-nearest neighbors\n",
    "cv_models.update( {\"knn\":KNeighborsClassifier()} )\n",
    "# Support Vector Classification Linear\n",
    "cv_models.update( {\"svcl\":LinearSVC(random_state=SEED, max_iter=3000)} )\n",
    "# Support Vector Classification Polynomial\n",
    "cv_models.update( {\"svcp\":SVC(kernel=\"poly\", random_state=SEED, max_iter=3000)} )\n",
    "# Support Vector Classification Rbf\n",
    "cv_models.update( {\"svcr\":SVC(kernel=\"rbf\", random_state=SEED, max_iter=3000)} )\n",
    "# Mini-Batch K-Means\n",
    "#cv_models.update( {\"mbkmeans\":MiniBatchKMeans(random_state=SEED)} )\n",
    "# random forest\n",
    "cv_models.update( {\"rf\":RandomForestClassifier(random_state=SEED)} )\n",
    "# Stochastic Gradient Descent Classifier\n",
    "cv_models.update( {\"sgd\":SGDClassifier(random_state=SEED, max_iter=3000)} )\n",
    "# Logistic Regression\n",
    "cv_models.update( {\"lr\":LogisticRegression(random_state=SEED, max_iter=1000)} )\n",
    "# Multilayer Perceptron\n",
    "cv_models.update( {\"mlp\":MLPClassifier(random_state=SEED, max_iter=1000)} ) \n",
    "# Extreme Gradiente Boost\n",
    "cv_models.update( {\"xgb\":XGBClassifier()} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cross validation of model: dtc\n",
      "Training cross validation of model: gnb\n",
      "Training cross validation of model: knn\n",
      "Training cross validation of model: svcl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cross validation of model: svcp\n",
      "Training cross validation of model: svcr\n",
      "Training cross validation of model: rf\n",
      "Training cross validation of model: sgd\n",
      "Training cross validation of model: lr\n",
      "Training cross validation of model: mlp\n",
      "Training cross validation of model: xgb\n"
     ]
    }
   ],
   "source": [
    "cv_scores = {}\n",
    "\n",
    "for cls in cv_models.keys():\n",
    "  print(f\"Training cross validation of model: {cls}\")\n",
    "  score = np.mean(cross_val_score(cv_models[cls], X_train, y_train))\n",
    "  cv_scores.update( {cls: score} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtc': 0.6569815254531766,\n",
       " 'gnb': 0.7527834082997111,\n",
       " 'knn': 0.6734754155325188,\n",
       " 'svcl': 0.4804585497062476,\n",
       " 'svcp': 0.7215645772604132,\n",
       " 'svcr': 0.7215645772604132,\n",
       " 'rf': 0.7649742926455733,\n",
       " 'sgd': 0.7215645772604132,\n",
       " 'lr': 0.7743106632433093,\n",
       " 'mlp': 0.6741588000231655,\n",
       " 'xgb': 0.7308880780937306}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'C': loguniform(1e-4, 1e4),  # Regularização (inverso da força de regularização)\n",
    "    'penalty': ['l1', 'l2'],  # Tipo de penalidade\n",
    "    'solver': ['liblinear', 'saga'],  # Algoritmo de otimização\n",
    "    'max_iter': [100, 200, 300]  # Número máximo de iterações\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5, verbose=1, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000250A2ECFC10>,\n",
       "                                        'max_iter': [100, 200, 300],\n",
       "                                        'penalty': ['l1', 'l2'],\n",
       "                                        'solver': ['liblinear', 'saga']},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = random_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = random_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'C': 38.25784206216524, 'max_iter': 300, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Melhor pontuação: 0.7782543886308051\n"
     ]
    }
   ],
   "source": [
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "print(best_params)\n",
    "print(f\"Melhor pontuação: {best_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
