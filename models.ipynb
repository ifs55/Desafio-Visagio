{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "## Ensembles\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import auc, roc_curve, RocCurveDisplay\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "\n",
    "# Seleção de Feature \n",
    "from sklearn.feature_selection import SelectFromModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 265123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('data_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Abandono_curso'], axis=1)\n",
    "y = df['Abandono_curso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_range_finder\n",
    "models = {}\n",
    "# decision tree classifier\n",
    "models.update( {\"dtc\":DecisionTreeClassifier(random_state=SEED)} )\n",
    "# Gaussian Naive Bayes - testar\n",
    "models.update( {\"gnb\":GaussianNB()} )\n",
    "# k-nearest neighbors\n",
    "models.update( {\"knn\":KNeighborsClassifier()} )\n",
    "# Support Vector Classification Linear\n",
    "models.update( {\"svcl\":LinearSVC(random_state=SEED)} )\n",
    "# Support Vector Classification Polynomial\n",
    "models.update( {\"svcp\":SVC(kernel=\"poly\", random_state=SEED, max_iter=3000)} )\n",
    "# Support Vector Classification Rbf\n",
    "models.update( {\"svcr\":SVC(kernel=\"rbf\", random_state=SEED, max_iter=3000)} )\n",
    "# Mini-Batch K-Means\n",
    "#models.update( {\"mbkmeans\":MiniBatchKMeans(random_state=SEED)} )\n",
    "# random forest\n",
    "models.update( {\"rf\":RandomForestClassifier(random_state=SEED)} )\n",
    "# Stochastic Gradient Descent Classifier\n",
    "models.update( {\"sgd\":SGDClassifier(random_state=SEED)} )\n",
    "# Logistic Regression\n",
    "models.update( {\"lr\":LogisticRegression(random_state=SEED, max_iter=1000)} )\n",
    "# Multilayer Perceptron\n",
    "models.update( {\"mlp\":MLPClassifier(random_state=SEED, max_iter=1000)} ) \n",
    "# Extreme Gradiente Boost\n",
    "models.update( {\"xgb\":XGBClassifier()} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: dtc\n",
      "Training model: gnb\n",
      "Training model: knn\n",
      "Training model: svcl\n",
      "Training model: svcp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: svcr\n",
      "Training model: rf\n",
      "Training model: sgd\n",
      "Training model: lr\n",
      "Training model: mlp\n",
      "Training model: xgb\n"
     ]
    }
   ],
   "source": [
    "trained_models = {}\n",
    "for cls in models.keys():\n",
    "  print(f\"Training model: {cls}\")\n",
    "  trained_models.update({cls:models[cls].fit(X_train, y_train)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving predictions from model: dtc\n",
      "Retrieving predictions from model: gnb\n",
      "Retrieving predictions from model: knn\n",
      "Retrieving predictions from model: svcl\n",
      "Retrieving predictions from model: svcp\n",
      "Retrieving predictions from model: svcr\n",
      "Retrieving predictions from model: rf\n",
      "Retrieving predictions from model: sgd\n",
      "Retrieving predictions from model: lr\n",
      "Retrieving predictions from model: mlp\n",
      "Retrieving predictions from model: xgb\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "for cls in trained_models.keys():\n",
    "  print(f\"Retrieving predictions from model: {cls}\")\n",
    "  predictions.update({cls:trained_models[cls].predict(X_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracies = {}\n",
    "class_rep = {}\n",
    "conf_matr = {}\n",
    "\n",
    "for pred in predictions.keys():\n",
    "  # accuracy scores\n",
    "  accuracies.update( { pred: accuracy_score(y_test, predictions[pred]) } )\n",
    "  # classification reports\n",
    "  class_rep.update( { pred: classification_report(y_test, predictions[pred]) } )\n",
    "  # confusion matrixes\n",
    "  conf_matr.update( { pred: confusion_matrix(y_test, predictions[pred]) } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtc': 0.6759956942949408,\n",
       " 'gnb': 0.759956942949408,\n",
       " 'knn': 0.6663078579117331,\n",
       " 'svcl': 0.3573735199138859,\n",
       " 'svcp': 0.7158234660925726,\n",
       " 'svcr': 0.7158234660925726,\n",
       " 'rf': 0.7631862217438106,\n",
       " 'sgd': 0.28417653390742736,\n",
       " 'lr': 0.7771797631862217,\n",
       " 'mlp': 0.7631862217438106,\n",
       " 'xgb': 0.7416576964477933}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Model: dtc\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.45      0.44       264\n",
      "           1       0.78      0.77      0.77       665\n",
      "\n",
      "    accuracy                           0.68       929\n",
      "   macro avg       0.60      0.61      0.61       929\n",
      "weighted avg       0.68      0.68      0.68       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: gnb\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.30      0.41       264\n",
      "           1       0.77      0.94      0.85       665\n",
      "\n",
      "    accuracy                           0.76       929\n",
      "   macro avg       0.72      0.62      0.63       929\n",
      "weighted avg       0.75      0.76      0.72       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: knn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.16      0.21       264\n",
      "           1       0.72      0.87      0.79       665\n",
      "\n",
      "    accuracy                           0.67       929\n",
      "   macro avg       0.52      0.51      0.50       929\n",
      "weighted avg       0.61      0.67      0.62       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: svcl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.91      0.44       264\n",
      "           1       0.79      0.14      0.24       665\n",
      "\n",
      "    accuracy                           0.36       929\n",
      "   macro avg       0.54      0.52      0.34       929\n",
      "weighted avg       0.65      0.36      0.30       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: svcp\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       264\n",
      "           1       0.72      1.00      0.83       665\n",
      "\n",
      "    accuracy                           0.72       929\n",
      "   macro avg       0.36      0.50      0.42       929\n",
      "weighted avg       0.51      0.72      0.60       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: svcr\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       264\n",
      "           1       0.72      1.00      0.83       665\n",
      "\n",
      "    accuracy                           0.72       929\n",
      "   macro avg       0.36      0.50      0.42       929\n",
      "weighted avg       0.51      0.72      0.60       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: rf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.28      0.40       264\n",
      "           1       0.77      0.96      0.85       665\n",
      "\n",
      "    accuracy                           0.76       929\n",
      "   macro avg       0.74      0.62      0.63       929\n",
      "weighted avg       0.75      0.76      0.72       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: sgd\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.99      0.44       264\n",
      "           1       0.50      0.00      0.01       665\n",
      "\n",
      "    accuracy                           0.28       929\n",
      "   macro avg       0.39      0.50      0.22       929\n",
      "weighted avg       0.44      0.28      0.13       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: lr\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.24      0.38       264\n",
      "           1       0.77      0.99      0.86       665\n",
      "\n",
      "    accuracy                           0.78       929\n",
      "   macro avg       0.84      0.61      0.62       929\n",
      "weighted avg       0.81      0.78      0.73       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: mlp\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.17      0.29       264\n",
      "           1       0.75      1.00      0.86       665\n",
      "\n",
      "    accuracy                           0.76       929\n",
      "   macro avg       0.86      0.59      0.58       929\n",
      "weighted avg       0.81      0.76      0.70       929\n",
      "\n",
      "------------------------------------------\n",
      "Model: xgb\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.35      0.43       264\n",
      "           1       0.78      0.90      0.83       665\n",
      "\n",
      "    accuracy                           0.74       929\n",
      "   macro avg       0.68      0.62      0.63       929\n",
      "weighted avg       0.72      0.74      0.72       929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cf in class_rep.keys():\n",
    "  print('------------------------------------------')\n",
    "  print(f\"Model: {cf}\")\n",
    "  print(class_rep[cf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_models = {}\n",
    "# decision tree classifier\n",
    "cv_models.update( {\"dtc\":DecisionTreeClassifier(random_state=SEED)} )\n",
    "# Gaussian Naive Bayes - testar\n",
    "cv_models.update( {\"gnb\":GaussianNB()} )\n",
    "# k-nearest neighbors\n",
    "cv_models.update( {\"knn\":KNeighborsClassifier()} )\n",
    "# Support Vector Classification Linear\n",
    "cv_models.update( {\"svcl\":LinearSVC(random_state=SEED, max_iter=3000)} )\n",
    "# Support Vector Classification Polynomial\n",
    "cv_models.update( {\"svcp\":SVC(kernel=\"poly\", random_state=SEED, max_iter=3000)} )\n",
    "# Support Vector Classification Rbf\n",
    "cv_models.update( {\"svcr\":SVC(kernel=\"rbf\", random_state=SEED, max_iter=3000)} )\n",
    "# Mini-Batch K-Means\n",
    "#cv_models.update( {\"mbkmeans\":MiniBatchKMeans(random_state=SEED)} )\n",
    "# random forest\n",
    "cv_models.update( {\"rf\":RandomForestClassifier(random_state=SEED)} )\n",
    "# Stochastic Gradient Descent Classifier\n",
    "cv_models.update( {\"sgd\":SGDClassifier(random_state=SEED, max_iter=3000)} )\n",
    "# Logistic Regression\n",
    "cv_models.update( {\"lr\":LogisticRegression(random_state=SEED, max_iter=1000)} )\n",
    "# Multilayer Perceptron\n",
    "cv_models.update( {\"mlp\":MLPClassifier(random_state=SEED, max_iter=1000)} ) \n",
    "# Extreme Gradiente Boost\n",
    "cv_models.update( {\"xgb\":XGBClassifier()} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cross validation of model: dtc\n",
      "Training cross validation of model: gnb\n",
      "Training cross validation of model: knn\n",
      "Training cross validation of model: svcl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cross validation of model: svcp\n",
      "Training cross validation of model: svcr\n",
      "Training cross validation of model: rf\n",
      "Training cross validation of model: sgd\n",
      "Training cross validation of model: lr\n",
      "Training cross validation of model: mlp\n",
      "Training cross validation of model: xgb\n"
     ]
    }
   ],
   "source": [
    "cv_scores = {}\n",
    "\n",
    "for cls in cv_models.keys():\n",
    "  print(f\"Training cross validation of model: {cls}\")\n",
    "  score = np.mean(cross_val_score(cv_models[cls], X_train, y_train))\n",
    "  cv_scores.update( {cls: score} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtc': 0.6569815254531766,\n",
       " 'gnb': 0.7527834082997111,\n",
       " 'knn': 0.6734754155325188,\n",
       " 'svcl': 0.4804585497062476,\n",
       " 'svcp': 0.7215645772604132,\n",
       " 'svcr': 0.7215645772604132,\n",
       " 'rf': 0.7649742926455733,\n",
       " 'sgd': 0.7215645772604132,\n",
       " 'lr': 0.7743106632433093,\n",
       " 'mlp': 0.6741588000231655,\n",
       " 'xgb': 0.7308880780937306}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'alpha': np.logspace(-4, 0, num=5),  # Varia de 0.0001 a 1\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'max_iter': [1000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator=mlp,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=200,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 180 is smaller than n_iter=200. Running 180 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=MLPClassifier(), n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={'activation': ['relu', 'tanh',\n",
       "                                                       'logistic'],\n",
       "                                        'alpha': array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00]),\n",
       "                                        'hidden_layer_sizes': [(50,), (100,),\n",
       "                                                               (50, 50),\n",
       "                                                               (100, 50)],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'invscaling',\n",
       "                                                          'adaptive'],\n",
       "                                        'max_iter': [1000]},\n",
       "                   random_state=265123, verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 1000,\n",
       " 'learning_rate': 'invscaling',\n",
       " 'hidden_layer_sizes': (100,),\n",
       " 'alpha': 1.0,\n",
       " 'activation': 'relu'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7577961815408969"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
